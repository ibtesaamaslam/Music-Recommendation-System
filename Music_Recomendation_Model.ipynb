{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OicqUMnWk196",
        "outputId": "45994197-8241-4bc8-9c11-67ff23abacc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.13.1)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357294 sha256=69e582b32e2a4a4aa57fff36099f2a86b99f1e30d65ae2d0b539f15dd04595ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"gauravduttakiit/million-song-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aIJL28q9RKx",
        "outputId": "f69c1092-1be6-402a-8411-42e608309ad7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/gauravduttakiit/million-song-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225M/225M [00:05<00:00, 46.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/gauravduttakiit/million-song-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import surprise\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Load the built-in MovieLens dataset ('ml-100k') from Surprise\n",
        "# This dataset is for movie recommendations, but we'll use the same structure for music later\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# Use Singular Value Decomposition (SVD) algorithm for collaborative filtering\n",
        "model = SVD()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(trainset)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.test(testset)\n",
        "\n",
        "# Calculate accuracy metrics (e.g., RMSE)\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "# Cross-validate the model using 5-fold cross-validation\n",
        "cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Example: Predict whether a specific user will like a specific movie\n",
        "user_id = '196'  # Replace with a real user_id from the MovieLens dataset\n",
        "item_id = '302'  # Replace with a real item_id (movie_id) from the dataset\n",
        "pred = model.predict(user_id, item_id)\n",
        "print(f'Predicted rating for user {user_id} on item {item_id}: {pred.est}')\n",
        "\n",
        "# Function to recommend items for a user (top 5 movies not yet rated by the user)\n",
        "def recommend_items(user_id, model, n_recommendations=5):\n",
        "    item_ids = trainset.all_items()\n",
        "    user_items = [i for (i, _) in trainset.ur[trainset.to_inner_uid(user_id)]]\n",
        "    recommendations = []\n",
        "    for item_id in item_ids:\n",
        "        if item_id not in user_items:  # Only recommend items the user hasn't interacted with\n",
        "            pred = model.predict(user_id, str(trainset.to_raw_iid(item_id)))\n",
        "            recommendations.append((item_id, pred.est))\n",
        "    # Sort recommendations by predicted rating\n",
        "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "    return recommendations[:n_recommendations]\n",
        "\n",
        "# Get top 5 movie recommendations for a user (user 196 in MovieLens dataset)\n",
        "recommendations = recommend_items('196', model)\n",
        "print(\"Top 5 recommendations for user 196:\")\n",
        "for item_id, score in recommendations:\n",
        "    print(f'Item: {trainset.to_raw_iid(item_id)}, Predicted rating: {score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9VcTHlHZmIu",
        "outputId": "1e7fd570-47e5-4187-ef58-4a75f25829f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "RMSE: 0.9383\n",
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9311  0.9431  0.9324  0.9383  0.9329  0.9355  0.0045  \n",
            "MAE (testset)     0.7350  0.7447  0.7324  0.7388  0.7356  0.7373  0.0042  \n",
            "Fit time          1.42    1.44    1.43    1.81    1.93    1.61    0.22    \n",
            "Test time         0.12    0.29    0.18    0.21    0.24    0.21    0.06    \n",
            "Predicted rating for user 196 on item 302: 4.676594004230606\n",
            "Top 5 recommendations for user 196:\n",
            "Item: 50, Predicted rating: 4.783768368593216\n",
            "Item: 169, Predicted rating: 4.775462507174807\n",
            "Item: 302, Predicted rating: 4.676594004230606\n",
            "Item: 178, Predicted rating: 4.670202862754224\n",
            "Item: 408, Predicted rating: 4.601255541328325\n"
          ]
        }
      ]
    }
  ]
}